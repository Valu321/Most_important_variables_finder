import streamlit as st
import pandas as pd
import numpy as np
from pycaret.classification import *
from pycaret.regression import *
import plotly.express as px
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split
import openai
import os
from dotenv import load_dotenv
from langfuse.decorators import langfuse_context, observe
from langfuse.openai import openai as langfuse_openai
import warnings
warnings.filterwarnings('ignore')

# ZaÅ‚aduj zmienne Å›rodowiskowe
load_dotenv()

# Konfiguracja Langfuse
try:
    LANGFUSE_PUBLIC_KEY = os.getenv('LANGFUSE_PUBLIC_KEY')
    LANGFUSE_SECRET_KEY = os.getenv('LANGFUSE_SECRET_KEY')
    LANGFUSE_HOST = os.getenv('LANGFUSE_HOST', 'https://cloud.langfuse.com')
    
    if LANGFUSE_PUBLIC_KEY and LANGFUSE_SECRET_KEY:
        langfuse_openai.api_key = os.getenv('OPENAI_API_KEY')
        langfuse_openai.langfuse.public_key = LANGFUSE_PUBLIC_KEY
        langfuse_openai.langfuse.secret_key = LANGFUSE_SECRET_KEY
        langfuse_openai.langfuse.host = LANGFUSE_HOST
        LANGFUSE_ENABLED = True
    else:
        LANGFUSE_ENABLED = False
except:
    LANGFUSE_ENABLED = False

# Konfiguracja strony
st.set_page_config(
    page_title="Analiza NajwaÅ¼niejszych Cech",
    page_icon="ðŸ“Š",
    layout="wide"
)

# TytuÅ‚ aplikacji
st.title("ðŸ“Š Aplikacja do znajdowania najwaÅ¼niejszych cech w zbiorze danych")
st.markdown("---")

# Funkcja do okreÅ›lenia typu problemu
def determine_problem_type(data, target_column):
    """OkreÅ›la czy problem to klasyfikacja czy regresja."""
    target_data = data[target_column]

    # JeÅ›li ma maÅ‚o unikalnych wartoÅ›ci wzglÄ™dem rozmiaru zbioru â†’ klasyfikacja
    unique_values = target_data.nunique(dropna=True)
    total_values = len(target_data)
    if total_values > 0 and unique_values / total_values < 0.2:
        return "klasyfikacja"

    # JeÅ¼eli wiÄ™kszoÅ›Ä‡ wartoÅ›ci daje siÄ™ bezpiecznie zrzutowaÄ‡ na liczby â†’ regresja
    numeric_data = pd.to_numeric(target_data, errors='coerce')
    non_numeric_ratio = numeric_data.isna().mean()
    if non_numeric_ratio < 0.1:
        return "regresja"

    return "klasyfikacja"

# Funkcja do analizy waÅ¼noÅ›ci cech
def analyze_feature_importance(data, target_column, problem_type):
    """Analizuje waÅ¼noÅ›Ä‡ cech uÅ¼ywajÄ…c PyCaret"""
    
    # Przygotowanie danych
    
    # 1. UsuÅ„ kolumny z duÅ¼Ä… liczbÄ… wartoÅ›ci brakujÄ…cych
    data_clean = data.dropna(thresh=len(data) * 0.7, axis=1)
    
    # 2. UsuÅ„ wiersze z wartoÅ›ciami brakujÄ…cymi
    data_clean = data_clean.dropna()

    # 3. SprawdÅº, czy kolumna docelowa przetrwaÅ‚a czyszczenie
    if target_column not in data_clean.columns:
        return None, f"Kolumna docelowa '{target_column}' zostaÅ‚a usuniÄ™ta podczas czyszczenia (prawdopodobnie miaÅ‚a zbyt wiele brakujÄ…cych wartoÅ›ci)."

    if len(data_clean) < 10:
        return None, "Za maÅ‚o danych po czyszczeniu"
    
    # === POCZÄ„TEK POPRAWIONEGO BLOKU ===
    # Ten blok 'try...except' musi byÄ‡ WEWNÄ„TRZ funkcji
    try:
        if problem_type == "klasyfikacja":
            # Konfiguracja PyCaret dla klasyfikacji
            # Zmieniono nazwÄ™ zmiennej, aby uniknÄ…Ä‡ konfliktu z importem (clf)
            setup_env = setup(
                data_clean,
                target=target_column,
                session_id=123
            )
            
            # PorÃ³wnanie modeli
            best_model = compare_models(include=['rf', 'xgboost', 'lightgbm'], verbose=False)
            
            # === POPRAWIONA LOGIKA ===
            # Pobierz nazwy cech BEZPOÅšREDNIO z PyCaret (po transformacjach)
            feature_names = get_config('X_train_transformed').columns
            
            # Pobierz waÅ¼noÅ›ci z modelu
            importances = best_model.feature_importances_ if hasattr(best_model, 'feature_importances_') else [0] * len(feature_names)
            
            # Sprawdzenie (choÄ‡ teraz powinno byÄ‡ zawsze rÃ³wne)
            if len(feature_names) != len(importances):
                 return None, f"BÅ‚Ä…d wewnÄ™trzny: NiezgodnoÅ›Ä‡ cech ({len(feature_names)}) i waÅ¼noÅ›ci ({len(importances)})."

            # Tworzenie DataFrame
            importance_df = pd.DataFrame({
                'Feature': feature_names,
                'Importance': importances
            })
            
        else:  # regresja
            # Konfiguracja PyCaret dla regresji
            # Zmieniono nazwÄ™ zmiennej
            setup_env = setup(
                data_clean,
                target=target_column,
                session_id=123
            )
            
            # PorÃ³wnanie modeli
            best_model = compare_models(include=['rf', 'xgboost', 'lightgbm'], verbose=False)
            
            # === POPRAWIONA LOGIKA ===
            # Pobierz nazwy cech BEZPOÅšREDNIO z PyCaret (po transformacjach)
            feature_names = get_config('X_train_transformed').columns
            
            # Pobierz waÅ¼noÅ›ci z modelu
            importances = best_model.feature_importances_ if hasattr(best_model, 'feature_importances_') else [0] * len(feature_names)

            # Sprawdzenie
            if len(feature_names) != len(importances):
                 return None, f"BÅ‚Ä…d wewnÄ™trzny: NiezgodnoÅ›Ä‡ cech ({len(feature_names)}) i waÅ¼noÅ›ci ({len(importances)})."

            # Tworzenie DataFrame
            importance_df = pd.DataFrame({
                'Feature': feature_names,
                'Importance': importances
            })
        
        # Sortuj wedÅ‚ug waÅ¼noÅ›ci
        importance_df = importance_df.sort_values('Importance', ascending=False)
        
        return importance_df, best_model
        
    except Exception as e:
        return None, f"BÅ‚Ä…d podczas analizy: {str(e)}"
    # === KONIEC POPRAWIONEGO BLOKU ===

# Funkcja do generowania opisu przez OpenAI
def generate_description_with_gpt(importance_df, problem_type, target_column, data_info, api_key=None):
    """Generuje opis sÅ‚owny wynikÃ³w uÅ¼ywajÄ…c OpenAI API"""
    
    if importance_df is None or len(importance_df) == 0:
        return "Nie udaÅ‚o siÄ™ wygenerowaÄ‡ opisu z powodu bÅ‚Ä™dÃ³w w analizie."
    
    # SprawdÅº czy klucz API jest dostÄ™pny (z parametru lub z pliku .env)
    if not api_key:
        api_key = os.getenv('OPENAI_API_KEY')
    
    if not api_key:
        return """
## âš ï¸ Brak klucza API

Aby wygenerowaÄ‡ opis przez ChatGPT, wprowadÅº klucz OpenAI API w panelu po lewej stronie lub dodaj go do pliku `.env`.

**Tymczasowy opis:**
NajwaÅ¼niejsze cechy zostaÅ‚y zidentyfikowane w tabeli powyÅ¼ej. 
NajwyÅ¼sza waÅ¼noÅ›Ä‡: **{0}** ({1:.1f}%).
        """.format(
            importance_df.iloc[0]['Feature'],
            (importance_df.iloc[0]['Importance'] / importance_df['Importance'].sum()) * 100
        )
    
    try:
        # Konfiguracja OpenAI - nowy interfejs z Langfuse
        from openai import OpenAI
        
        # UÅ¼yj Langfuse wrapper jeÅ›li jest skonfigurowany
        if LANGFUSE_ENABLED:
            client = langfuse_openai
        else:
            client = OpenAI(api_key=api_key)
        
        # Przygotuj dane dla GPT
        top_features = importance_df.head(10)
        features_text = "\n".join([
            f"{i+1}. {row['Feature']}: {row['Importance']:.4f}" 
            for i, (_, row) in enumerate(top_features.iterrows())
        ])
        
        # Prompt dla GPT
        prompt = f"""
JesteÅ› ekspertem w analizie danych i machine learning. Przeanalizuj wyniki analizy waÅ¼noÅ›ci cech i wygeneruj profesjonalny opis.

DANE:
- Typ problemu: {problem_type}
- Kolumna docelowa: {target_column}
- Liczba cech: {len(importance_df)}
- Informacje o danych: {data_info}

NAJWAÅ»NIEJSZE CECHY:
{features_text}

Wygeneruj opis zawierajÄ…cy:
1. Podsumowanie analizy
2. InterpretacjÄ™ najwaÅ¼niejszych cech
3. Praktyczne wnioski biznesowe
4. Konkretne rekomendacje

Odpowiedz w jÄ™zyku polskim, w formacie Markdown, profesjonalnie ale przystÄ™pnie.
"""
        
        # WywoÅ‚anie API - z obsÅ‚ugÄ… Langfuse
        if LANGFUSE_ENABLED:
            # UÅ¼yj wrappera Langfuse do automatycznego Å›ledzenia
            langfuse_context.update_current_trace(
                name="generate_feature_analysis",
                user_id=st.session_state.get('user_id', 'anonymous'),
                metadata={
                    'problem_type': problem_type,
                    'target_column': target_column,
                    'num_features': len(importance_df)
                }
            )
        
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "JesteÅ› ekspertem w analizie danych i machine learning. Odpowiadaj profesjonalnie w jÄ™zyku polskim."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1000,
            temperature=0.7
        )
        
        return f"## ðŸ¤– Analiza wygenerowana przez ChatGPT\n\n{response.choices[0].message.content}"
        
    except Exception as e:
        return f"""
## âŒ BÅ‚Ä…d podczas generowania opisu

Nie udaÅ‚o siÄ™ wygenerowaÄ‡ opisu przez ChatGPT: {str(e)}

**Podstawowe informacje:**
- Typ problemu: {problem_type}
- Kolumna docelowa: {target_column}
- NajwaÅ¼niejsza cecha: {importance_df.iloc[0]['Feature']}
- Liczba analizowanych cech: {len(importance_df)}
        """

# GÅ‚Ã³wna aplikacja
def main():
    # Sidebar dla wczytywania pliku
    st.sidebar.header("ðŸ“ Wczytaj dane")
    
    uploaded_file = st.sidebar.file_uploader(
        "Wybierz plik CSV",
        type=['csv'],
        help="Wczytaj plik CSV z danymi do analizy"
    )
    
    # Pole do wprowadzenia klucza OpenAI API
    st.sidebar.header("ðŸ”‘ Konfiguracja ChatGPT")
    openai_api_key = st.sidebar.text_input(
        "Klucz OpenAI API (opcjonalnie)",
        type="password",
        help="WprowadÅº klucz API, aby korzystaÄ‡ z automatycznego generowania opisÃ³w przez ChatGPT"
    )
    
    if uploaded_file is not None:
        try:
            # Wczytanie danych
            data = pd.read_csv(uploaded_file, sep=None, engine='python')
            
            st.sidebar.success(f"âœ… Wczytano {len(data)} wierszy i {len(data.columns)} kolumn")
            
            # WyÅ›wietlenie podstawowych informacji o danych
            st.header("ðŸ“Š PodglÄ…d danych")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("Pierwsze 5 wierszy")
                st.dataframe(data.head())
            
            with col2:
                st.subheader("Podstawowe statystyki")
                st.dataframe(data.describe())
            
            # WybÃ³r kolumny docelowej
            st.header("ðŸŽ¯ WybÃ³r kolumny docelowej")
            
            target_column = st.selectbox(
                "Wybierz kolumnÄ™ docelowÄ…:",
                options=data.columns,
                help="Wybierz kolumnÄ™, dla ktÃ³rej chcesz znaleÅºÄ‡ najwaÅ¼niejsze cechy"
            )
            
            if st.button("ðŸ” Rozpocznij analizÄ™", type="primary"):
                with st.spinner("AnalizujÄ™ dane..."):
                    # OkreÅ›lenie typu problemu
                    problem_type = determine_problem_type(data, target_column)
                    
                    st.header(f"ðŸ¤– Typ problemu: {problem_type.title()}")
                    st.info(f"System automatycznie rozpoznaÅ‚, Å¼e to problem **{problem_type}**")
                    
                    # Analiza waÅ¼noÅ›ci cech
                    importance_df, model = analyze_feature_importance(data, target_column, problem_type)
                    
                    if importance_df is not None:
                        st.header("ðŸ“ˆ NajwaÅ¼niejsze cechy")
                        
                        # Wykres waÅ¼noÅ›ci cech
                        fig = px.bar(
                            importance_df.head(10),
                            x='Importance',
                            y='Feature',
                            orientation='h',
                            title="Top 10 najwaÅ¼niejszych cech",
                            color='Importance',
                            color_continuous_scale='viridis'
                        )
                        fig.update_layout(height=500)
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # Tabela z wynikami
                        st.subheader("ðŸ“‹ SzczegÃ³Å‚owe wyniki")
                        st.dataframe(importance_df, use_container_width=True)
                        
                        # Generowanie opisu przez ChatGPT
                        st.header("ðŸ“ Opis wynikÃ³w")
                        
                        # Przygotuj informacje o danych
                        data_info = f"ZbiÃ³r zawiera {len(data)} wierszy i {len(data.columns)} kolumn. Typ problemu: {problem_type}."
                        
                        with st.spinner("ðŸ¤– GenerujÄ™ opis przez ChatGPT..."):
                            description = generate_description_with_gpt(importance_df, problem_type, target_column, data_info, openai_api_key)
                            st.markdown(description)
                        
                    else:
                        st.error(f"âŒ {model}")
                        
        except Exception as e:
            st.error(f"âŒ BÅ‚Ä…d podczas wczytywania pliku: {str(e)}")
    
    else:
        # Instrukcje dla uÅ¼ytkownika
        st.info("ðŸ‘† Wczytaj plik CSV z danymi, aby rozpoczÄ…Ä‡ analizÄ™")
        
        st.markdown("""
        ## ðŸš€ Jak uÅ¼ywaÄ‡ aplikacji:
        
        1. **Wczytaj dane** - uÅ¼yj panelu po lewej stronie, aby wczytaÄ‡ plik CSV
        2. **Wybierz kolumnÄ™ docelowÄ…** - okreÅ›l, ktÃ³rÄ… kolumnÄ™ chcesz przewidywaÄ‡
        3. **Rozpocznij analizÄ™** - aplikacja automatycznie:
           - OkreÅ›li typ problemu (klasyfikacja/regresja)
           - Zbuduje najlepszy model
           - WyÅ›wietli najwaÅ¼niejsze cechy
           - Wygeneruje opis wynikÃ³w przez ChatGPT ðŸ¤–
        
        ## ðŸ“‹ Wymagania dla danych:
        - Format CSV
        - Co najmniej 10 wierszy danych
        - Kolumny numeryczne lub kategoryczne
        - Maksymalnie 70% wartoÅ›ci brakujÄ…cych w kolumnach
        
        """)

if __name__ == "__main__":
    # Streamlit automatycznie uÅ¼yje PORT z --server.port w run command
    # PORT jest ustawiany przez zmiennÄ… Å›rodowiskowÄ… $PORT w App Platform
    main()